{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import re\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GM_WEBPAGE = 'https://www.google.com/maps/'\n",
    "MAX_WAIT = 10\n",
    "MAX_RETRY = 5\n",
    "MAX_SCROLLS = 40 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogleMapsScrapper :\n",
    "    \n",
    "    def __init__(self, debug = False) :\n",
    "        \n",
    "        self.debug = debug\n",
    "        self.logger = self.__getlogger()\n",
    "        self.driver = self.__getdriver()\n",
    "    \n",
    "    def __enter__(self) :\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def __exit__(self,exc_type,exc_value,tb) :\n",
    "        \n",
    "        if exc_type is not None :\n",
    "            traceback.print_exception(exc_type,exc_value,tb)\n",
    "        \n",
    "        self.driver.close()\n",
    "        self.driver.quit()\n",
    "        return True\n",
    "        \n",
    "    def sort_by_date(self,url) :\n",
    "        \n",
    "        self.driver.get(url)\n",
    "        wait = WebDriverWait(self.driver,MAX_WAIT)\n",
    "        \n",
    "        clicked = False \n",
    "        tries = 0\n",
    "        \n",
    "        while not clicked and tries < MAX_RETRY :\n",
    "            try :\n",
    "                menu_bt = wait.until(EC.element_to_be_clickable((By.XPATH,'//button[@data-value=\\'Sort\\']')))\n",
    "                menu_bt.click()\n",
    "\n",
    "                clicked = True\n",
    "                time.sleep(3)\n",
    "            except Exception as e :\n",
    "                tries += 1 \n",
    "                self.logger.warn('failed to click button')\n",
    "            \n",
    "            if tries == MAX_RETRY :\n",
    "                return -1 \n",
    "            \n",
    "            \n",
    "        recent_rating_bt = self.driver.find_elements_by_xpath('//li[@role=\\'menuitemradio\\']')[1]\n",
    "        recent_rating_bt.click()\n",
    "        \n",
    "        time.sleep(5)\n",
    "        return 0\n",
    "    \n",
    "    def get_reviews(self,offset) :\n",
    "        \n",
    "        self.__scroll()\n",
    "        time.sleep(4)   \n",
    "        self.__expand_reviews()\n",
    "        \n",
    "        response = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "        rblock = response.find_all('div', class_ = 'section-review-content')\n",
    "        \n",
    "        parsed_reviews = []\n",
    "        for index, review in enumerate(rblock) :\n",
    "            if index >= offset :\n",
    "                parsed_reviews.append(self.__parse(review))\n",
    "                \n",
    "        return parsed_reviews\n",
    "    \n",
    "    \n",
    "    def get_account(self,url) :\n",
    "        \n",
    "        self.driver.get(url)\n",
    "        time.sleep(4)\n",
    "        \n",
    "        resp = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "        place_data = self.__parse_place(resp)\n",
    "        \n",
    "        return place_data\n",
    "        \n",
    "    def __parse(self,review) :\n",
    "        \n",
    "        item = {}\n",
    "        \n",
    "        id_review = review.find('button', class_='section-review-action-menu')['data-review-id']\n",
    "        username = review.find('div', class_='section-review-title').find('span').text\n",
    "        \n",
    "        try :\n",
    "            review_text = self.__filter_string(review.find('span',class_ = 'section-review-text').text)\n",
    "        \n",
    "        except Exception as e :\n",
    "            review_text = None\n",
    "            \n",
    "            \n",
    "        rating = float(review.find('span', class_ = 'section-review-stars')['aria-label'].split(' ')[1])\n",
    "        relative_date = review.find('span', class_ = 'section-review-publish-date').text\n",
    "        \n",
    "        try :\n",
    "            n_reviews_photos = review.find('div', class_ = 'section-review-subtitle').find_all('span')[1].text\n",
    "            metadata = n_reviews_photos.split('\\xe3\\x83\\xbb')\n",
    "            \n",
    "            if len(metadata) == 3 : \n",
    "                n_photos = int(metadata[2].split(' ')[0].replace('.', ''))\n",
    "            else:\n",
    "                n_photos = 0\n",
    "\n",
    "            idx = len(metadata)\n",
    "            n_reviews = int(metadata[idx - 1].split(' ')[0].replace('.', ''))\n",
    "\n",
    "        except Exception as e:\n",
    "            n_reviews = 0\n",
    "            n_photos = 0\n",
    "\n",
    "        user_url = review.find('a')['href']\n",
    "\n",
    "        item['id_review'] = id_review\n",
    "        item['caption'] = review_text\n",
    "\n",
    "        # depends on language, which depends on geolocation defined by Google Maps\n",
    "        # custom mapping to transform into date shuold be implemented\n",
    "        item['relative_date'] = relative_date\n",
    "\n",
    "        # store datetime of scraping and apply further processing to calculate\n",
    "        # correct date as retrieval_date - time(relative_date)\n",
    "        item['retrieval_date'] = datetime.now()\n",
    "        item['rating'] = rating\n",
    "        item['username'] = username\n",
    "        item['n_review_user'] = n_reviews\n",
    "        item['n_photo_user'] = n_photos\n",
    "        item['url_user'] = user_url\n",
    "\n",
    "        return item\n",
    "\n",
    "\n",
    "    def __parse_place(self, response):\n",
    "\n",
    "        place = {}\n",
    "        place['overall_rating'] = float(response.find('div', class_='gm2-display-2').text.replace(',', '.'))\n",
    "        place['n_reviews'] = int(response.find('div', class_='gm2-caption').text.replace('.', '').replace(',','').split(' ')[0])\n",
    "\n",
    "        return place\n",
    "\n",
    "    # expand review description\n",
    "    def __expand_reviews(self):\n",
    "        # use XPath to load complete reviews\n",
    "        links = self.driver.find_elements_by_xpath('//button[@class=\\'section-expand-review blue-link\\']')\n",
    "        for l in links:\n",
    "            l.click()\n",
    "        time.sleep(2)\n",
    "\n",
    "\n",
    "    def __scroll(self):\n",
    "        scrollable_div = self.driver.find_element_by_css_selector('div.section-layout.section-scrollbox.scrollable-y.scrollable-show')\n",
    "        self.driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', scrollable_div)\n",
    "\n",
    "\n",
    "    def __get_logger(self):\n",
    "        # create logger\n",
    "        logger = logging.getLogger('googlemaps-scraper')\n",
    "        logger.setLevel(logging.DEBUG)\n",
    "\n",
    "        # create console handler and set level to debug\n",
    "        fh = logging.FileHandler('gm-scraper.log')\n",
    "        fh.setLevel(logging.DEBUG)\n",
    "\n",
    "        # create formatter\n",
    "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "        # add formatter to ch\n",
    "        fh.setFormatter(formatter)\n",
    "\n",
    "        # add ch to logger\n",
    "        logger.addHandler(fh)\n",
    "\n",
    "        return logger\n",
    "\n",
    "\n",
    "    def __get_driver(self, debug=False):\n",
    "        options = Options()\n",
    "\n",
    "        if not self.debug:\n",
    "            options.add_argument(\"--headless\")\n",
    "        else:\n",
    "            options.add_argument(\"--window-size=1366,768\")\n",
    "\n",
    "        options.add_argument(\"--disable-notifications\")\n",
    "        options.add_argument(\"--lang=en-GB\")\n",
    "        input_driver = webdriver.Chrome(chrome_options=options)\n",
    "\n",
    "        return input_driver\n",
    "\n",
    "\n",
    "    # util function to clean special characters\n",
    "    def __filter_string(self, str):\n",
    "        strOut = str.replace('\\r', ' ').replace('\\n', ' ').replace('\\t', ' ')\n",
    "        return strOut"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
